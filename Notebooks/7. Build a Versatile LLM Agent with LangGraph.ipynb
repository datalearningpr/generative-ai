{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Versatile LLM Agent with LangGraph\n",
    "\n",
    "Large Language Models (LLMs) have revolutionized how we build different AI applications. AI Agents can handle tasks that require decision-making, real-world interactions, and autonomy. While there are many frameworks available, LangGraph stands out for its ability to create sophisticated agents with multiple capabilities. In this notebook, we'll explore how to build a practical LLM agent for an educational company, \"Best Courses,\" demonstrating three distinct use cases that showcase the versatility of LangGraph.\n",
    "\n",
    "This bot will handle three types of interactions:\n",
    "1. General company information (character-based responses)\n",
    "2. Course-specific queries (structured data handling)\n",
    "3. Enrollment FAQ assistance (unstructured data processing)\n",
    "\n",
    "These scenarios are thoughtfully selected to represent common real-world applications and showcase various aspects of agent development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install libraries\n",
    "!pip install langchain langchain-community langchain-experimental langchain-openai langgraph pandas tabulate PyMuPDF faiss-cpu fastembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load env variables from your local .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### langgraph state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### langgraph nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### general node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"openai/gpt-4o-2024-11-20\",\n",
    "openai_api_key = os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "openai_api_base = 'https://openrouter.ai/api/v1',)\n",
    "\n",
    "def general(state: State):\n",
    "    general_sys_prompt = \"\"\"\n",
    "    You are a chatbot for \"Best Courses\", you will only answer questions about the description below regarding \"Best Courses\". \n",
    "\n",
    "    Welcome to Best Courses - Where Excellence Meets Education\n",
    "Best Courses is a premier educational institute dedicated to transforming aspirations into achievements. Established in 2010, we have consistently maintained our position as a leading provider of quality education and professional development programs. Our institute stands as a beacon of academic excellence, offering a diverse range of courses designed to meet the evolving demands of today's competitive world.\n",
    "At Best Courses, we believe in the power of education to change lives. Our state-of-the-art facilities, coupled with an experienced faculty of industry experts and academicians, create an optimal learning environment that nurtures talent and fosters growth. We pride ourselves on maintaining small class sizes to ensure personalized attention and maximum interaction between students and instructors.\n",
    "Our Offerings:\n",
    "•\tProfessional certification courses\n",
    "•\tIndustry-specific skill development programs\n",
    "•\tLanguage proficiency classes\n",
    "•\tCareer counseling and placement assistance\n",
    "•\tSoft skills training\n",
    "•\tTechnical workshops\n",
    "•\tOnline and hybrid learning options\n",
    "What Sets Us Apart:\n",
    "1.\tIndustry-Aligned Curriculum: Our courses are regularly updated to reflect current industry trends and requirements.\n",
    "2.\tPractical Approach: We emphasize hands-on learning through real-world projects and case studies.\n",
    "3.\tExpert Faculty: Our instructors bring years of professional experience and academic excellence to the classroom.\n",
    "4.\tModern Infrastructure: Well-equipped classrooms, computer labs, and libraries provide all necessary resources for effective learning.\n",
    "5.\tFlexible Learning Options: We offer multiple batches, weekend classes, and online courses to accommodate various schedules.\n",
    "Success Track Record:\n",
    "•\tOver 50,000 students trained\n",
    "•\t90% placement rate\n",
    "•\t1000+ corporate tie-ups\n",
    "•\tAlumni working in leading organizations worldwide\n",
    "Our Vision:\n",
    "To be the most trusted name in education, creating future-ready professionals who excel in their chosen fields and contribute meaningfully to society.\n",
    "Our Mission:\n",
    "To provide high-quality, accessible education that empowers individuals with knowledge, skills, and confidence to achieve their professional goals.\n",
    "Whether you're a fresh graduate looking to enhance your employability, a professional seeking to upgrade your skills, or someone pursuing a career change, Best Courses offers the perfect platform to realize your dreams. Join us on your journey to success, and experience education that truly makes a difference.\n",
    "Transform your future with Best Courses - Where Learning Leads to Success!\n",
    "\n",
    "\"\"\"\n",
    "    return {\"messages\": [llm.invoke([SystemMessage(general_sys_prompt)]+state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### structured data driven answering node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "\n",
    "df = pd.read_csv(\"./courses.csv\")\n",
    "agent = create_pandas_dataframe_agent(llm, df, verbose=False, allow_dangerous_code=True, agent_executor_kwargs={\"handle_parsing_errors\": True})\n",
    "\n",
    "def courses(state: State):\n",
    "    ret = agent.invoke(state[\"messages\"][-1])\n",
    "    return { \"messages\": ret[\"output\"] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unstructured data RAG node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embeddings = FastEmbedEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "vector_store = FAISS.load_local(\"./faq\", embeddings,  allow_dangerous_deserialization=True)\n",
    "\n",
    "\n",
    "# if you did not build the local vector storage yet, you can use the below code to build\n",
    "\n",
    "# from langchain_community.document_loaders import PyMuPDFLoader\n",
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))\n",
    "# vector_store = FAISS(\n",
    "#     embedding_function=embeddings,\n",
    "#     index=index,\n",
    "#     docstore= InMemoryDocstore(),\n",
    "#     index_to_docstore_id={}\n",
    "# )\n",
    "# loader = PyMuPDFLoader(r\".\\FAQ.pdf\")\n",
    "# docs = loader.load()\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# all_splits = text_splitter.split_documents(docs)\n",
    "# _ = vector_store.add_documents(documents=all_splits)\n",
    "# vector_store.save_local(\"./faq\")\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"openai/gpt-4o-2024-11-20\",\n",
    "openai_api_key = os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "openai_api_base = 'https://openrouter.ai/api/v1',)\n",
    "\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {question} \n",
    "\n",
    "Context: {context} \n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "class RagState(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "def retrieve(state: RagState):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: RagState):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt_template.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "graph_builder = StateGraph(RagState).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "rag_graph = graph_builder.compile()\n",
    "\n",
    "\n",
    "def faq(state: State):\n",
    "    ret = rag_graph.invoke({\"question\": state[\"messages\"][-1].content})\n",
    "    return {\"messages\": ret[\"answer\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine the nodes and build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "\n",
    "def route_conversation(\n",
    "    state: State,\n",
    "):\n",
    "\n",
    "    route_sys_prompt = \"\"\"\n",
    "    Given the user input message, choose the best route.\n",
    "    \n",
    "    1. courses. if the user input message is related to inquiry about the courses information, e.g. Course Name, Title of Award, Awarding Institution,\n",
    "    Broad Discipline, Course Duration, Mode of Delivery, General Entry Requirement, Course Fee.\n",
    "\n",
    "    2. faq. if the user input is about course enrollment faq.\n",
    "\n",
    "    3. general. anything not related to 1 and 2.\n",
    "\n",
    "    You will only output \"courses\", \"faq\" or \"general\", without any quote.\n",
    "\"\"\"\n",
    "\n",
    "    response = llm.invoke([SystemMessage(route_sys_prompt), state[\"messages\"][-1]])\n",
    "\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"general\", general)\n",
    "graph_builder.add_node(\"faq\", faq)\n",
    "graph_builder.add_node(\"courses\", courses)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    START,\n",
    "    route_conversation,\n",
    "    {\"general\": \"general\", \"faq\": \"faq\", \"courses\": \"courses\"},\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"general\", END)\n",
    "graph_builder.add_edge(\"faq\", END)\n",
    "graph_builder.add_edge(\"courses\", END)\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### invoke the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"messages\": [\"how many courses can we choose?\"]})"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
